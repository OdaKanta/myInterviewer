import asyncio
import json
import base64
import websockets
import logging
import io
import wave
import audioop
from typing import AsyncGenerator, Optional, Callable
from django.conf import settings
from pydub import AudioSegment

logger = logging.getLogger(__name__)


class PCMConverter:
    """WebMã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’PCM16ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def webm_to_pcm16(webm_data: bytes, sample_rate: int = 16000) -> bytes:
        """WebMãƒ‡ãƒ¼ã‚¿ã‚’PCM16å½¢å¼ã«å¤‰æ›ï¼ˆè¤‡æ•°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå¯¾å¿œï¼‰"""
        try:
            print(f"ğŸ”„ [PCM CONVERTER] Converting {len(webm_data)} bytes to PCM16")
            
            # æœ€åˆã«WebMã¨ã—ã¦å‡¦ç†ã‚’è©¦è¡Œ
            formats_tried = []
            audio = None
            
            try:
                audio = AudioSegment.from_file(io.BytesIO(webm_data), format="webm")
                print(f"âœ… [PCM CONVERTER] Decoded as WebM")
            except Exception as e:
                formats_tried.append(f"webm: {e}")
                # WebMãŒå¤±æ•—ã—ãŸå ´åˆã€ä»–ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è©¦è¡Œ
                try:
                    audio = AudioSegment.from_file(io.BytesIO(webm_data), format="ogg")
                    print(f"âœ… [PCM CONVERTER] Decoded as OGG")
                except Exception as e2:
                    formats_tried.append(f"ogg: {e2}")
                    try:
                        audio = AudioSegment.from_file(io.BytesIO(webm_data), format="mp4")
                        print(f"âœ… [PCM CONVERTER] Decoded as MP4")
                    except Exception as e3:
                        formats_tried.append(f"mp4: {e3}")
                        # æœ€å¾Œã®æ‰‹æ®µï¼šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’è‡ªå‹•æ¤œå‡º
                        audio = AudioSegment.from_file(io.BytesIO(webm_data))
                        print(f"âœ… [PCM CONVERTER] Decoded with auto-detection")
            
            print(f"ğŸ“Š [PCM CONVERTER] Original: {audio.frame_rate}Hz, {audio.channels}ch, {len(audio)}ms")
            
            # 16kHz, mono, 16-bitã«å¤‰æ›
            audio = audio.set_frame_rate(sample_rate)
            audio = audio.set_channels(1)
            audio = audio.set_sample_width(2)  # 16-bit
            
            # raw PCMãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            pcm_data = audio.raw_data
            
            print(f"âœ… [PCM CONVERTER] PCM16 output: {len(pcm_data)} bytes ({sample_rate}Hz, mono, 16-bit)")
            return pcm_data
            
        except Exception as e:
            print(f"âŒ [PCM CONVERTER] Conversion failed: {e}")
            if formats_tried:
                print(f"    Attempted formats: {formats_tried}")
            logger.error(f"Failed to convert audio to PCM16: {e}")
            return b""
    
    @staticmethod
    def wav_to_pcm16(wav_data: bytes, sample_rate: int = 16000) -> bytes:
        """WAVãƒ‡ãƒ¼ã‚¿ã‚’PCM16å½¢å¼ã«å¤‰æ›"""
        try:
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with wave.open(io.BytesIO(wav_data), 'rb') as wav_file:
                frames = wav_file.readframes(wav_file.getnframes())
                
                # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆå¤‰æ›
                if wav_file.getframerate() != sample_rate:
                    frames = audioop.ratecv(
                        frames, 
                        wav_file.getsampwidth(), 
                        wav_file.getnchannels(),
                        wav_file.getframerate(), 
                        sample_rate, 
                        None
                    )[0]
                
                # ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
                if wav_file.getnchannels() == 2:
                    frames = audioop.tomono(frames, wav_file.getsampwidth(), 1, 1)
                
                # 16-bitå¤‰æ›
                if wav_file.getsampwidth() != 2:
                    frames = audioop.lin2lin(frames, wav_file.getsampwidth(), 2)
                
                logger.debug(f"Converted WAV to PCM16: {len(frames)} bytes")
                return frames
                
        except Exception as e:
            logger.error(f"Failed to convert WAV to PCM16: {e}")
            return b""



class RealtimeTranscriber:
    """OpenAI Realtime APIã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°è»¢å†™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, callback: Optional[Callable] = None):
        self.api_key = settings.OPENAI_API_KEY
        self.websocket = None
        self.is_connected = False
        self.callback = callback  # è»¢å†™çµæœã‚’å—ã‘å–ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
        self.session_id = None
        
    async def connect(self):
        """OpenAI Realtime APIã«æ¥ç¶šï¼ˆè»¢å†™å°‚ç”¨ãƒ¢ãƒ¼ãƒ‰ï¼‰"""
        try:
            # OpenAI Realtime API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆè»¢å†™å°‚ç”¨ï¼‰
            uri = "wss://api.openai.com/v1/realtime?intent=transcription"
            
            # èªè¨¼ãƒ˜ãƒƒãƒ€ãƒ¼
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "OpenAI-Beta": "realtime=v1"
            }
            
            # WebSocketæ¥ç¶š
            try:
                # æ–°ã—ã„websocketsãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å ´åˆ
                self.websocket = await websockets.connect(
                    uri,
                    additional_headers=headers,
                    timeout=10
                )
            except TypeError:
                # å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å ´åˆ
                self.websocket = await websockets.connect(
                    uri,
                    extra_headers=headers,
                    timeout=10
                )
            
            self.is_connected = True
            logger.info("Connected to OpenAI Realtime API (transcription mode)")
            
            # è»¢å†™å°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è¨­å®š
            await self._configure_transcription_session()
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒŠãƒ¼ã‚’é–‹å§‹
            asyncio.create_task(self._listen_for_messages())
            
            return True
            
        except Exception as e:
            logger.error(f"Failed to connect to OpenAI Realtime API: {e}")
            self.is_connected = False
            return False
    
    async def _configure_transcription_session(self):
        """è»¢å†™å°‚ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š"""
        try:
            # å‚è€ƒã‚³ãƒ¼ãƒ‰ã«åŸºã¥ãè»¢å†™å°‚ç”¨è¨­å®š
            config = {
                "type": "transcription_session.update",
                "session": {
                    "input_audio_transcription": {
                        "model": "gpt-4o-transcribe",
                    }
                }
            }
            
            await self.websocket.send(json.dumps(config))
            logger.info("Transcription session configuration sent")
            
        except Exception as e:
            logger.error(f"Failed to configure transcription session: {e}")
            self.is_connected = False
    
    async def _listen_for_messages(self):
        """OpenAI ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç›£è¦–"""
        try:
            async for message in self.websocket:
                data = json.loads(message)
                await self._handle_message(data)
        except websockets.exceptions.ConnectionClosed:
            logger.info("Connection to OpenAI closed")
            self.is_connected = False
        except Exception as e:
            logger.error(f"Error in message listener: {e}")
            self.is_connected = False
    
    async def _handle_message(self, data):
        """OpenAIã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‡¦ç†ï¼ˆè»¢å†™å°‚ç”¨ï¼‰"""
        message_type = data.get("type")
        
        if message_type == "session.created":
            self.session_id = data.get("session", {}).get("id")
            logger.info(f"Transcription session created: {self.session_id}")
            
        elif message_type == "conversation.item.input_audio_transcription.delta":
            # éƒ¨åˆ†è»¢å†™çµæœï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰
            delta_text = data.get("delta", "")
            if delta_text and self.callback:
                await self.callback({
                    "type": "transcription_partial",
                    "text": delta_text,
                    "is_partial": True
                })
                
        elif message_type == "conversation.item.input_audio_transcription.completed":
            # è»¢å†™å®Œäº†
            transcript = data.get("transcript", "")
            if transcript and self.callback:
                await self.callback({
                    "type": "transcription_completed",
                    "text": transcript,
                    "is_final": True
                })
                
        elif message_type == "input_audio_buffer.speech_started":
            # éŸ³å£°æ¤œå‡ºé–‹å§‹
            if self.callback:
                await self.callback({
                    "type": "speech_started"
                })
                
        elif message_type == "input_audio_buffer.speech_stopped":
            # éŸ³å£°æ¤œå‡ºåœæ­¢
            if self.callback:
                await self.callback({
                    "type": "speech_stopped"
                })
                
        elif message_type == "error":
            # ã‚¨ãƒ©ãƒ¼å‡¦ç†
            error = data.get("error", {})
            logger.error(f"OpenAI Realtime API error: {error}")
            if self.callback:
                await self.callback({
                    "type": "error",
                    "error": error
                })
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šãã®ä»–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã‚’ãƒ­ã‚°å‡ºåŠ›
        else:
            logger.debug(f"Received message type: {message_type}")
    
    async def send_audio_chunk(self, audio_data: bytes):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’OpenAIã«é€ä¿¡"""
        if not self.is_connected or not self.websocket:
            logger.warning("Not connected to OpenAI, cannot send audio")
            return
        
        try:
            # PCM16ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›ã•ã‚ŒãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            audio_base64 = base64.b64encode(audio_data).decode('utf-8')
            
            message = {
                "type": "input_audio_buffer.append",
                "audio": audio_base64
            }
            
            await self.websocket.send(json.dumps(message))
            
        except Exception as e:
            logger.error(f"Failed to send audio chunk: {e}")
    
    async def send_webm_chunk(self, webm_data: bytes):
        """WebMãƒ‡ãƒ¼ã‚¿ã‚’PCM16ã«å¤‰æ›ã—ã¦é€ä¿¡"""
        if not self.is_connected or not self.websocket:
            logger.warning("Not connected to OpenAI, cannot send WebM")
            return
        
        try:
            print(f"ğŸ¬ [REALTIME API] Converting WebM chunk: {len(webm_data)} bytes")
            
            # WebMã‚’PCM16ã«å¤‰æ›
            pcm_data = PCMConverter.webm_to_pcm16(webm_data)
            if pcm_data:
                await self.send_audio_chunk(pcm_data)
                print(f"âœ… [REALTIME API] Sent WebMâ†’PCM16: {len(pcm_data)} bytes")
            else:
                print(f"âŒ [REALTIME API] WebM conversion failed")
                
        except Exception as e:
            logger.error(f"Failed to send WebM chunk: {e}")
            print(f"âŒ [REALTIME API] WebM send error: {e}")
    
    async def commit_audio(self):
        """éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’ã‚³ãƒŸãƒƒãƒˆã—ã¦è»¢å†™ã‚’å®Ÿè¡Œ"""
        if not self.is_connected or not self.websocket:
            return
        
        try:
            message = {
                "type": "input_audio_buffer.commit"
            }
            await self.websocket.send(json.dumps(message))
            
        except Exception as e:
            logger.error(f"Failed to commit audio: {e}")
    
    async def clear_audio_buffer(self):
        """éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢"""
        if not self.is_connected or not self.websocket:
            return
        
        try:
            message = {
                "type": "input_audio_buffer.clear"
            }
            await self.websocket.send(json.dumps(message))
            
        except Exception as e:
            logger.error(f"Failed to clear audio buffer: {e}")
    
    async def disconnect(self):
        """OpenAI Realtime APIã‹ã‚‰åˆ‡æ–­"""
        if self.websocket:
            await self.websocket.close()
        self.is_connected = False
        logger.info("Disconnected from OpenAI Realtime API")


class PCMConverter:
    """WebMéŸ³å£°ã‚’PCM16ã«å¤‰æ›ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    async def webm_to_pcm16(webm_data: bytes) -> bytes:
        """WebMéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’PCM16ã«å¤‰æ›"""
        import subprocess
        import asyncio
        
        try:
            process = await asyncio.create_subprocess_exec(
                'ffmpeg',
                '-i', 'pipe:0',  # å…¥åŠ›: stdin
                '-f', 'wav',     # å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: WAV
                '-ar', '24000',  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: 24kHz (OpenAI Realtime APIæ¨å¥¨)
                '-ac', '1',      # ãƒãƒ£ãƒ³ãƒãƒ«æ•°: ãƒ¢ãƒãƒ©ãƒ«
                '-sample_fmt', 's16',  # ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ: 16bit
                'pipe:1',        # å‡ºåŠ›: stdout
                stdin=subprocess.PIPE,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate(input=webm_data)
            
            if process.returncode == 0:
                # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤å»ã—ã¦PCMãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
                if len(stdout) > 44:  # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã¯44ãƒã‚¤ãƒˆ
                    pcm_data = stdout[44:]  # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    return pcm_data
                else:
                    logger.warning("WAV data too short")
                    return b''
            else:
                logger.error(f"FFmpeg conversion failed: {stderr.decode()}")
                return b''
                
        except Exception as e:
            logger.error(f"Error converting WebM to PCM16: {e}")
            return b''
