import json
import asyncio
import base64
import logging
from typing import Dict, Any, Optional
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.contrib.auth.models import User
from .models import InterviewSession, Question, Answer
from .services import AudioProcessor, ExplanationAnalyzer

# ãƒ­ã‚°è¨­å®š
logger = logging.getLogger(__name__)


class InterviewConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.session_id = self.scope['url_route']['kwargs']['session_id']
        self.session_group_name = f'interview_{self.session_id}'
        
        # Join session group
        await self.channel_layer.group_add(
            self.session_group_name,
            self.channel_name
        )
        
        # AudioProcessorã‚’åˆæœŸåŒ–
        self.audio_processor = AudioProcessor()
        
        # Realtime APIè»¢å†™ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¨­å®š
        async def transcription_callback(data):
            await self.handle_realtime_transcription(data)
        
        # Realtime Transcriberã‚’åˆæœŸåŒ–ï¼ˆéåŒæœŸï¼‰
        try:
            success = await self.audio_processor.initialize_realtime_transcriber(transcription_callback)
            if success:
                print("Realtime transcription enabled for session")
            else:
                print("Falling back to standard transcription")
        except Exception as e:
            print(f"Realtime transcriber initialization failed: {e}")
        
        await self.accept()
    
    async def disconnect(self, close_code: int) -> None:
        """WebSocketåˆ‡æ–­å‡¦ç†"""
        # Realtime transcriberã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        if hasattr(self, 'audio_processor') and self.audio_processor.realtime_transcriber:
            try:
                await self.audio_processor.realtime_transcriber.disconnect()
            except Exception as e:
                logger.error(f"Error disconnecting realtime transcriber: {e}")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰é›¢è„±
        await self.channel_layer.group_discard(
            self.session_group_name,
            self.channel_name
        )
        logger.info(f"WebSocket disconnected for session {self.session_id}")

    async def handle_realtime_transcription(self, data: Dict[str, Any]) -> None:
        """Realtime API ã‹ã‚‰ã®è»¢å†™çµæœã‚’å‡¦ç†"""
        message_type = data.get("type")
        
        response_map = {
            "transcription_partial": {
                'type': 'streaming_transcription',
                'text': data.get('text', ''),
                'is_partial': True
            },
            "transcription_completed": {
                'type': 'transcription_result',
                'text': data.get('text', ''),
                'is_final': True,
                'is_partial': False
            },
            "speech_started": {
                'type': 'speech_detected',
                'status': 'started'
            },
            "speech_stopped": {
                'type': 'speech_detected',
                'status': 'stopped'
            },
            "error": {
                'type': 'audio_error',
                'message': f"Realtime API error: {data.get('error', {}).get('message', 'Unknown error')}"
            }
        }
        
        if message_type in response_map:
            await self.send(text_data=json.dumps(response_map[message_type]))
        else:
            logger.warning(f"Unknown realtime transcription message type: {message_type}")
    
    async def receive(self, text_data: str) -> None:
        """WebSocketãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡å‡¦ç†"""
        try:
            data = json.loads(text_data)
            message_type = data.get('type')
            
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
            handler_map = {
                'audio_chunk': self.handle_audio_chunk,
                'text_input': self.handle_text_input,
                'session_control': self.handle_session_control
            }
            
            if message_type in handler_map:
                await handler_map[message_type](data)
            else:
                logger.warning(f"Unknown message type: {message_type}")
                
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON received: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': 'Invalid JSON format'
            }))
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            await self.send(text_data=json.dumps({
                'type': 'error',
                'message': 'Message processing failed'
            }))
    
    async def handle_audio_chunk(self, data: Dict[str, Any]) -> None:
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        audio_data = data.get('audio_data')
        is_final = data.get('is_final', False)
        chunk_id = data.get('chunk_id', 0)
        
        logger.info(f"ğŸ¤ Audio chunk {chunk_id}: final={is_final}, size={len(base64.b64decode(audio_data)) if audio_data else 0}B")
        
        if not hasattr(self, 'audio_processor'):
            self.audio_processor = AudioProcessor()
        
        try:
            if is_final and audio_data:
                # æœ€çµ‚ãƒãƒ£ãƒ³ã‚¯ã®ã¿å‡¦ç†
                transcribed_text = await database_sync_to_async(
                    self.audio_processor.transcribe_audio
                )(audio_data)
                
                if transcribed_text and transcribed_text.strip():
                    await self.send(text_data=json.dumps({
                        'type': 'transcription_result',
                        'text': transcribed_text.strip(),
                        'is_final': True,
                        'chunk_id': chunk_id
                    }))
                else:
                    await self.send(text_data=json.dumps({
                        'type': 'audio_error',
                        'message': 'No transcription result'
                    }))
            else:
                # ä¸­é–“ãƒãƒ£ãƒ³ã‚¯ã¯å—ä¿¡ç¢ºèªã®ã¿
                await self.send(text_data=json.dumps({
                    'type': 'audio_received',
                    'status': 'received',
                    'chunk_id': chunk_id
                }))
                    
        except Exception as e:
            logger.error(f"Audio processing error for chunk {chunk_id}: {e}")
            await self.send(text_data=json.dumps({
                'type': 'audio_error',
                'message': f'Audio processing failed: {str(e)}',
                'chunk_id': chunk_id
            }))

    async def _handle_streaming_chunk(self, audio_data: str, chunk_id: int, processing_hint: str, chunk_type: str) -> None:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†"""
        is_pydub_preferred = processing_hint == 'pydub_preferred' or chunk_type == 'streaming_pydub'
        
        # Realtime transcriberã‚’åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿ï¼‰
        await self._ensure_realtime_transcriber()
        
        if self._is_realtime_available():
            # Realtime APIä½¿ç”¨
            result = await self.audio_processor.process_realtime_audio_chunk_v2(
                audio_data, 
                self.audio_processor.realtime_transcriber
            )
            status = 'pydub_realtime_processing' if is_pydub_preferred else 'realtime_processing'
            await self._send_audio_received(chunk_id, status if result == "PROCESSING" else status.replace('processing', 'waiting'))
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            result = self.audio_processor.process_audio_chunk_streaming(audio_data)
            if result and result.strip():
                await self._send_transcription_result(result.strip(), True, chunk_id, 'fallback')
            else:
                status = 'pydub_fallback_buffering' if is_pydub_preferred else 'fallback_buffering'
                await self._send_audio_received(chunk_id, status)

    async def _handle_final_chunk(self, audio_data: str, chunk_id: int, processing_hint: str, audio_format: str) -> None:
        """æœ€çµ‚éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã®å‡¦ç†"""
        is_pydub_preferred = processing_hint == 'pydub_preferred'
        
        logger.info(f"Processing final chunk {chunk_id}, Pydub preferred: {is_pydub_preferred}, format: {audio_format}")
        
        if self._is_realtime_available():
            # Realtime APIã§ã‚³ãƒŸãƒƒãƒˆ
            await self.audio_processor.commit_realtime_audio()
            method = 'pydub_realtime' if is_pydub_preferred else 'realtime'
            await self._send_audio_received(chunk_id, f'{method}_final_committed', method)
        else:
            # å¾“æ¥ã®è»¢å†™æ–¹å¼
            transcribed_text = await database_sync_to_async(
                self.audio_processor.transcribe_audio
            )(audio_data)
            
            if transcribed_text and transcribed_text.strip():
                method = 'pydub_fallback' if is_pydub_preferred else 'fallback'
                await self._send_transcription_result(transcribed_text.strip(), False, chunk_id, method)
            else:
                error_msg = 'Pydub transcription failed' if is_pydub_preferred else 'Transcription failed'
                await self._send_error_response(chunk_id, error_msg)

    async def _ensure_realtime_transcriber(self) -> None:
        """Realtime transcriberã®åˆæœŸåŒ–ã‚’ç¢ºä¿"""
        if not hasattr(self.audio_processor, 'realtime_transcriber') or not self.audio_processor.realtime_transcriber:
            await self.audio_processor.initialize_realtime_transcriber(self.handle_realtime_transcription)

    def _is_realtime_available(self) -> bool:
        """Realtime APIãŒåˆ©ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return (hasattr(self.audio_processor, 'realtime_transcriber') and 
                self.audio_processor.realtime_transcriber and 
                self.audio_processor.realtime_transcriber.is_connected)

    async def _send_transcription_result(self, text: str, is_partial: bool, chunk_id: int, method: str) -> None:
        """è»¢å†™çµæœã‚’é€ä¿¡"""
        await self.send(text_data=json.dumps({
            'type': 'streaming_transcription' if is_partial else 'transcription_result',
            'text': text,
            'is_partial': is_partial,
            'is_final': not is_partial,
            'chunk_id': chunk_id,
            'processing_method': method
        }))

    async def _send_audio_received(self, chunk_id: int, status: str, method: Optional[str] = None) -> None:
        """éŸ³å£°å—ä¿¡ç¢ºèªã‚’é€ä¿¡"""
        response = {
            'type': 'audio_received',
            'status': status,
            'chunk_id': chunk_id
        }
        if method:
            response['processing_method'] = method
        await self.send(text_data=json.dumps(response))

    async def _send_error_response(self, chunk_id: int, message: str) -> None:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’é€ä¿¡"""
        await self.send(text_data=json.dumps({
            'type': 'audio_error',
            'message': message,
            'chunk_id': chunk_id
        }))
    
    async def handle_text_input(self, data):
        """ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å‡¦ç†"""
        text = data.get('text')
        input_type = data.get('input_type')  # 'explanation' or 'answer'
        
        if input_type == 'explanation':
            await self.process_explanation(text)
        elif input_type == 'answer':
            await self.process_answer(text, data.get('question_id'))
    
    async def process_explanation(self, text):
        """èª¬æ˜ã‚’å‡¦ç†ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º"""
        session = await database_sync_to_async(
            InterviewSession.objects.get
        )(id=self.session_id)
        
        # èª¬æ˜ã‚’åˆ†æã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º
        analyzer = ExplanationAnalyzer()
        topics = await database_sync_to_async(
            analyzer.analyze_explanation
        )(text, session.material)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºçµæœã‚’é€ä¿¡
        await self.send(text_data=json.dumps({
            'type': 'topics_extracted',
            'topics': topics
        }))
    
    async def process_answer(self, text, question_id):
        """å›ç­”ã‚’å‡¦ç†"""
        # å›ç­”ã‚’ä¿å­˜
        answer = await database_sync_to_async(
            self.save_answer
        )(question_id, text)
        
        # ç†è§£åº¦ã‚’è©•ä¾¡
        from question_engine.services import AnswerEvaluator
        evaluator = AnswerEvaluator()
        evaluation = await database_sync_to_async(
            evaluator.evaluate_answer
        )(answer)
        
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«è©•ä¾¡çµæœã‚’é€ä¿¡
        await self.send(text_data=json.dumps({
            'type': 'answer_evaluated',
            'evaluation': evaluation,
            'needs_deeper_questioning': evaluation.get('needs_deeper_questioning', False)
        }))
    
    def save_answer(self, question_id, text):
        """å›ç­”ã‚’ä¿å­˜"""
        question = Question.objects.get(id=question_id)
        answer = Answer.objects.create(
            question=question,
            content=text
        )
        return answer
    
    async def handle_session_control(self, data):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¶å¾¡"""
        action = data.get('action')
        
        if action == 'start_questioning':
            await self.start_questioning_phase()
        elif action == 'pause_session':
            await self.pause_session()
        elif action == 'end_session':
            await self.end_session()
    
    async def start_questioning_phase(self):
        """è³ªå•ãƒ•ã‚§ãƒ¼ã‚ºã‚’é–‹å§‹"""
        session = await database_sync_to_async(
            InterviewSession.objects.get
        )(id=self.session_id)
        
        session.status = 'questioning'
        await database_sync_to_async(session.save)()
        
        await self.send(text_data=json.dumps({
            'type': 'phase_changed',
            'phase': 'questioning'
        }))
    
    async def pause_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä¸€æ™‚åœæ­¢"""
        session = await database_sync_to_async(
            InterviewSession.objects.get
        )(id=self.session_id)
        
        session.status = 'paused'
        await database_sync_to_async(session.save)()
        
        await self.send(text_data=json.dumps({
            'type': 'session_paused'
        }))
    
    async def end_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†"""
        session = await database_sync_to_async(
            InterviewSession.objects.get
        )(id=self.session_id)
        
        session.status = 'completed'
        await database_sync_to_async(session.save)()
        
        await self.send(text_data=json.dumps({
            'type': 'session_ended'
        }))
    
    # Group message handlers
    async def new_question(self, event):
        """æ–°ã—ã„è³ªå•ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡"""
        await self.send(text_data=json.dumps({
            'type': 'new_question',
            'question': event['question']
        }))
    
    async def timeout_warning(self, event):
        """ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè­¦å‘Šã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é€ä¿¡"""
        await self.send(text_data=json.dumps({
            'type': 'timeout_warning',
            'remaining_seconds': event['remaining_seconds']
        }))
